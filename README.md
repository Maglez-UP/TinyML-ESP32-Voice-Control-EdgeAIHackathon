# TinyML-ESP32-Voice-Control-EdgeAIHackathon
TinyML Speech Command Recognition on ESP32 using Edge Impulse for Edge AI Hackathon 2025.

Overview

This project implements a TinyML-based speech command recognition system running entirely on an ESP32 microcontroller with an INMP441 I2S microphone, enabling real-time, offline voice control with ultra-low power consumption.

The system is trained and optimized using Edge Impulse, incorporating a tuned MFCC pipeline, a 1D CNN architecture, and EON Compiler quantization to deliver a highly efficient embedded ML solution.

The result is a fully on-device speech command recognizer capable of understanding six spoken commands while operating without cloud connectivity, making it ideal for IoT, robotics, home automation, wearables, and remote deployments.

Features

Real-time on-device inference (266 ms latency)

High recognition confidence (97.1% average inference confidence)

Offline operation (no internet required)

Fully quantized model (int8) optimized with EON Compiler

Low memory usage (37% RAM and 27% ROM reduction)

High noise rejection (99.6% confidence for noise class)

Built with standard, low-cost hardware (ESP32 + MEMS I2S Mic)

Commands Recognized

forward

backward

left

right

stop

noise (background rejection)

Dataset

Based on a curated subset of the Google Speech Commands Dataset

1,500 samples per command

Additional noise augmentation using Himel’s Python curation script

Dataset split: 70% training, 30% validation

Preprocessing and MFCC extraction performed inside Edge Impulse

Methodology
1. Feature Extraction – MFCC

Optimized MFCC parameters:

20 MFCC coefficients

40 mel filterbanks

FFT Length: 256

Frame Length: 17.5 ms

Frame Stride: 25 ms

Pre-emphasis: 0.96

These values were selected through a trade-off between accuracy, spectral richness, and real-time efficiency.

2. Neural Network

A compact but effective 1D CNN architecture:

4 convolutional blocks

Batch Normalization

MaxPooling layers

Dense Softmax output layer

Dropout 0.35 to reduce overfitting

Trained for 110 epochs, batch size 32

Optimizer: Adam (0.0025 LR)

3. Deployment Workflow

Post-processing calibration (optimized FAR/FRR, threshold 0.46)

Quantization to int8

EON Compiler optimization

Exported as Arduino Library

Integrated into ESP32 firmware

Running with INMP441 I2S microphone

Performance
Edge Impulse Testing Performance

Accuracy: 87.14%

Balanced precision, recall, F1-score

On-Device Inference (ESP32)

Average confidence: 97.1%

Noise rejection: 99.6%

Latency: 266 ms total (DSP + NN inference)

Comparison with State-of-the-Art

Your model achieves competitive performance compared to published embedded speech recognition systems, despite using far more limited hardware.

Study	Model	Platform	Accuracy	Notes
TripletLoss-Res15	TripletLoss ResNet	Raspberry Pi 3B+	98.56%	Runs on SBC, not MCU
Sharifuddin et al.	2D CNN + MFCC	Raspberry Pi 3B+	95.3%	Higher-power hardware
Sutikno et al.	CNN + MFCC	Raspberry Pi 3	90%	SBC-level resources
Al-Rousan et al.	FNN + DWT	TI DSP Kit	98%	High-end DSP
Sutikno et al.	CNN + LSTM	Raspberry Pi 3	97.8%	Requires larger memory
This project	1D CNN + MFCC (Quantized)	ESP32 MCU	87.14%	Real-time, ultra-low-power, fully on-device TinyML
Hardware Requirements

ESP32-WROOM-32 microcontroller

INMP441 I2S MEMS microphone

USB cable

Optional: Breadboard & jumper wires

Software Requirements

Edge Impulse Studio

Arduino IDE

ESP32 Arduino Core

Python 3.x (for dataset curation)

Installation & Usage
1. Clone this repository
git clone https://github.com/<your-username>/TinyML-ESP32-Voice-Control

2. Install dependencies

Install the ESP32 boards package in Arduino IDE

Install required Arduino libraries (automatically included in Edge Impulse export)

3. Upload Firmware

Open the .ino file generated by Edge Impulse

Select correct ESP32 board

Flash it to the device

4. Test

Open the serial monitor and speak the commands near the microphone.
The predicted label and confidence scores will appear in real-time.

Project Structure
/dataset/         # Curated audio samples (optional)
/edge_impulse/    # Exported model files
/firmware/        # Arduino deployment code
/scripts/         # Himel-based curation scripts
/docs/            # Figures, matrices, tables, and report sections
README.md

Applications

Offline voice-controlled IoT

Low-power robotics

Industrial automation

Assistive devices

Smart home interfaces

Wearables and portable devices

Built With

Edge Impulse

TensorFlow Lite for Microcontrollers

ESP32-WROOM-32

INMP441 I2S Microphone

Arduino IDE

Python (Himel’s dataset curation)

Google Speech Commands Dataset

C/C++ firmware
